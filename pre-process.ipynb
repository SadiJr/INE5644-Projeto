{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc8e4117",
   "metadata": {},
   "source": [
    "## Grupo 7\n",
    "\n",
    "   #### Participantes na primeira entrega:\n",
    "       Lucas Santos de Oliveira\n",
    "       Lucas Madaloni Meira Varella\n",
    "       Nathan Sargon Werlich\n",
    "       Sadi Júnior Domingos Jacinto\n",
    "        \n",
    "   #### Participantes na segunda entrega:\n",
    "       Sadi Júnior Domingos Jacinto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15845696",
   "metadata": {},
   "source": [
    "### Entendimento dos Dados (_Data Understanding_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223d9962",
   "metadata": {},
   "source": [
    "1. Coleta inicial dos dados:\n",
    "  - Foi utilizado o _dataset_ _owid-covid-data.csv_, contido no repositório [https://github.com/owid/covid-19-data](https://github.com/owid/covid-19-data), que pode ser encontrado nesse [_link_](https://covid.ourworldindata.org/data/owid-covid-data.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e2436",
   "metadata": {},
   "source": [
    "2. Descrição dos Dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa4d235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9dc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para garantir que o presente notebook seja funcional mesmo estando offline, foi adicionado o dataset em anexo.\n",
    "# Caso queira utilizar o dataset on-line, descomente a linha abaixo e depois comente a última linha dessa cédula\n",
    "# data = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')\n",
    "data = pd.read_csv('owid-covid-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811c3d3",
   "metadata": {},
   "source": [
    "Vamos iniciar analisando quais são os tipos de dados disponíveis, sua quantidade, a correlação entre as variáveis e uma breve visualização humana também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f030dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf405dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Por existirem muitas colunas, é necessário configurar o pandas para exibir todas.\n",
    "pd.set_option('max_column', None)\n",
    "pd.set_option('max_row', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d19797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c9841",
   "metadata": {},
   "source": [
    "Aqui percebemos algumas coisas interessantes:\n",
    "\n",
    "- O atributo _date_, é uma data no formato yyyy-mm-dd, mas está sendo interpretado pelo pandas como um object ou, mais precisamente, uma str. Logo de cara encontramos uma necessidade de transformação de tipos.\n",
    "- Existe uma quantidade muito grande de valores NaN, que devem ser tratados, seja por inferência ou remoção.\n",
    "- Existem diversos valores numéricos, como _population_ que deveriam ser inteiros mas estão sendo interpretados como _float_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d97e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40102c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2384f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(data.corr(), annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd59669b",
   "metadata": {},
   "source": [
    "Como deve ter ficado claro na análise de correlação entre as variáveis nas duas células acima, o número de atributos é grande o suficiente para dificultar a visualização e análise dos mesmos. Vamos, então, analisar a descrição oficial de cada um desses atributos, acessível nesse [link](https://github.com/owid/covid-19-data/blob/master/public/data/owid-covid-codebook.csv).\n",
    "\n",
    "Por se tratar de uma atividade bastante extensa, e para não lotar esse notebook de informações textuais que ninguém vai ler de fato, essa etapa não será detalhada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153bbf88",
   "metadata": {},
   "source": [
    "Após ser realizado o estudo do significado de cada um dos atributos, devemos verificar a qualidade dos mesmos, à saber:\n",
    "- Valores faltantes ou nulos\n",
    "- Valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437da2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e69e0",
   "metadata": {},
   "source": [
    "Uma visualização gráfica desses dados nulos pode ser feita usando a biblioteca missingno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(data, figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f9edb",
   "metadata": {},
   "source": [
    "### Preparação de Dados (_Data Preparation_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37262bbd",
   "metadata": {},
   "source": [
    "1. Seleção de Dados:  \n",
    "De forma resumida, as colunas que nos interessam são:\n",
    "  - iso_code: Sigla do País\n",
    "  - continent: continente do país\n",
    "  - location: nome do país\n",
    "  - date: data do registro\n",
    "  - total_cases: número total de casos confirmados de COVID-19\n",
    "  - new_cases: novos casos confirmados de COVID-19\n",
    "  - new_cases_smoothed: novos casos confirmados de COVID-19 (com suavização de 7 dias)\n",
    "  - total_deaths: mortes confirmadas por COVID-19\n",
    "  - new_deaths: novas mortes confirmadas por COVID-19\n",
    "  - new_deaths_smoothed: novas mortes confirmadas por COVID-19 (com suavização de 7 dias)\n",
    "  - total_cases_per_million: número total de casos confirmados de COVID-19 por milhão\n",
    "  - new_cases_per_million: novos casos confirmados de COVID-19 por milhão\n",
    "  - new_cases_smoothed_per_million: novos casos confirmados de COVID-19 por milhão (com suavização de 7 dias)\n",
    "  - total_deaths_per_million: mortes confirmadas por COVID-19 por milhão\n",
    "  - new_deaths_per_million: novas mortes confirmadas por COVID-19 por milhão\n",
    "  - new_deaths_smoothed_per_million: novas mortes confirmadas por COVID-19 por milhão (com suavização de 7 dias)\n",
    "  - reproduction_rate: taxa de reprodução do vírus\n",
    "  - hosp_patients: Número de pacientes em um hospital com COVID-19 na data\n",
    "  - hosp_patients_per_million: Número de pacientes em um hospital com COVID-19 na data por milhão\n",
    "  - weekly_hosp_admissions: número de pacientes com COVID-19 admitidos em hospitais por semana.\n",
    "  - weekly_hosp_admissions_per_million: número de pacientes com COVID-19 admitidos em hospitais por semana por milhão.\n",
    "  - new_tests: novos testes de COVID-19\n",
    "  - total_tests: total de testes de COVID-19\n",
    "  - total_tests_per_thousand: total de testes de COVID-19 a cada 1000 pessoas\n",
    "  - new_tests_per_thousand: novos testes de COVID-19 a cada 1000 pessoas\n",
    "  - new_tests_smoothed: novos testes de COVID-19 com suavização de 7 dias\n",
    "  - new_tests_smoothed_per_thousand: novos testes de COVID-19 com suavização de 7 dias a cada 1000 pessoas\n",
    "  - positive_rate: taxa de positivação dos testes\n",
    "  - total_vaccinations: total de vacinas aplicadas\n",
    "  - people_vaccinated: total de pessoas que receberam ao menos uma dose da vacina\n",
    "  - people_fully_vaccinated: total de pessoas que receberam todas as doses da vacina\n",
    "  - new_vaccinations: novas vacinas aplicadas\n",
    "  - new_vaccinations_smoothed: novas vacinas aplicadas por semana.\n",
    "  - total_vaccinations_per_hundred: total de vacinas a cada 100 pessoas\n",
    "  - people_vaccinated_per_hundred: total de pessoas que tomaram ao menos uma dose a cada 100 pessoas\n",
    "  - people_fully_vaccinated_per_hundred: total de pessoas que tomaram todas as doses a cada 100 pessoas\n",
    "  - new_vaccinations_smoothed_per_million: novas vacinações aplicadas por semana a cada 1 milhão de pessoas\n",
    "  - population: população do país em 2020\n",
    "  - median_age: média da idade da população em 2020\n",
    "  - aged_65_older: porcentagem da população com mais de 65 anos\n",
    "  - aged_70_older: porcentagem da população com mais de 70 anos\n",
    "  - gdp_per_capita: poder de compra da população usando o valor do dolar em 2011.\n",
    "  - extreme_poverty: porcentagem da população vivendo em extrema pobreza.\n",
    "  - female_smokers: porcentagem de mulheres fumantes na população\n",
    "  - male_smokers: porcentagem de homens fumantes na população\n",
    "  - handwashing_facilities: porcentagem da população com acesso à \"lavar as mãos\"\n",
    "  - hospital_beds_per_thousand: vagas no hospital por 1000 pessoas \n",
    "  - life_expectancy: expectativa de vida da população do país\n",
    "  - human_development_index: IDH do país"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15229cf",
   "metadata": {},
   "source": [
    "Com os atributos selecionados, precisamos, agora, criar um novo Dataframe apenas com esses atributos e refazer nossa análise inicial dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f00b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['iso_code', 'continent', 'location', 'date', 'total_cases', 'new_cases', 'new_cases_smoothed',\n",
    "              'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_cases_per_million', \n",
    "              'new_cases_per_million', 'new_cases_smoothed_per_million', 'total_deaths_per_million',\n",
    "              'new_deaths_per_million', 'new_deaths_smoothed_per_million', 'reproduction_rate',\n",
    "              'hosp_patients', 'hosp_patients_per_million', 'weekly_hosp_admissions', \n",
    "              'weekly_hosp_admissions_per_million', 'new_tests', 'total_tests', 'total_tests_per_thousand',\n",
    "              'new_tests_per_thousand', 'new_tests_smoothed', 'new_tests_smoothed_per_thousand',\n",
    "              'positive_rate', 'total_vaccinations', 'people_vaccinated', 'people_fully_vaccinated',\n",
    "              'new_vaccinations', 'new_vaccinations_smoothed', 'total_vaccinations_per_hundred',\n",
    "              'people_vaccinated_per_hundred', 'people_fully_vaccinated_per_hundred',\n",
    "              'new_vaccinations_smoothed_per_million', 'population', 'median_age', 'aged_65_older',\n",
    "              'aged_70_older', 'gdp_per_capita', 'extreme_poverty', 'female_smokers', 'male_smokers',\n",
    "              'handwashing_facilities', 'hospital_beds_per_thousand', 'life_expectancy', 'human_development_index']\n",
    "\n",
    "dataset = data[attributes].copy()\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(dataset.corr(), annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47765849",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f018a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cac1e5",
   "metadata": {},
   "source": [
    "Vamos, primeiro, tratar dos poucos valores categóricos que temos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['iso_code'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3171a",
   "metadata": {},
   "source": [
    "Precisamos converter os valores iniciados com \"OWID\" para o formato aceitado de apenas três letras. E depois remover as linhas que pertencem a países que não existem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['iso_code'] = dataset['iso_code'].replace({'OWID_AFR': 'AFR', 'OWID_ASI': 'ASI', 'OWID_EUR': 'EUR',\n",
    "                                           'OWID_EUN': 'EUN', 'OWID_INT': 'INT', 'OWID_KOS': 'KOS',\n",
    "                                           'OWID_NAM': 'NAM', 'OWID_CYN': 'CYN', 'OWID_OCE': 'OCE',\n",
    "                                           'OWID_SAM': 'SAM', 'OWID_WRL': 'WRL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d86a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc\n",
    "from iso3166 import countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8204e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_find = []\n",
    "\n",
    "for country in dataset['iso_code'].unique():\n",
    "    try:\n",
    "        #print(f'Working in country {country}')\n",
    "        countries.get(country)\n",
    "    except:\n",
    "        print(f'Can not find country {country}')\n",
    "        not_find.append(country)\n",
    "\n",
    "mask = dataset['iso_code'].isin(not_find)\n",
    "dataset = dataset[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0bd086",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = set()\n",
    "def verify_geography(x):\n",
    "    iso_code = x['iso_code']\n",
    "    country = countries.get(iso_code)\n",
    "    country_name = country.name\n",
    "    try:\n",
    "        alpha2 = country.alpha2\n",
    "        continent_code = pc.country_alpha2_to_continent_code(alpha2)\n",
    "        continent_name = pc.convert_continent_code_to_continent_name(continent_code)\n",
    "        if x['continent'] == '' or x['continent'] != continent_name:\n",
    "            #print(f\"continent name in database is {x['continent']} and real value is {continent_name}\")\n",
    "            x['continent'] = continent_name\n",
    "        if x['location'] != country_name:\n",
    "            #print(f\"Location name in database is {x['location']} and real value is {country_name}\")\n",
    "            x['location'] = country_name\n",
    "        return x\n",
    "    except:\n",
    "        uniques.add(f'O que está dando erro é o {iso_code}')\n",
    "        #traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3781b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.apply(lambda x: verify_geography(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e45ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[dataset['iso_code'].isin(['PCN', 'SXM', 'TLS', 'VAT'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce51325e",
   "metadata": {},
   "source": [
    "Por se tratarem de poucos dados, e a maioria com valores NaN, não há problema em os remover."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac825422",
   "metadata": {},
   "source": [
    "Vamos, agora, converter a data para datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70de0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date'] = pd.to_datetime(dataset['date'], format='%Y-%m-%d')\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2af733",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.date.describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d91271",
   "metadata": {},
   "source": [
    "Vamos, finalmente, tratar dos dados nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f02e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d082cfc",
   "metadata": {},
   "source": [
    "Como existem diversos valores nulos, vamos dropar as linhas que possuem todos os dados nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d28245",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12468c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.isna().sum())\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59f6f5",
   "metadata": {},
   "source": [
    "Como ainda sobraram muitos dados nulos, vamos agora dropar todas as linhas que possuam 39 ou mais atributos nulos, já que uma linha com essa quantidade de atributos nulos não somente não será útil, como será extremamente, se não impossível, de inferir.\n",
    "\n",
    "Embora, ainda estejamos analisando essa situação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a328a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(thresh=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b2370",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.isna().sum())\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c83ac",
   "metadata": {},
   "source": [
    "Grande parte do _dataset_, como é possível perceber, foi removido. O que significa que esse _dataset_ escolhido é bastante \"poluído\". Porém, a quantidade restante ainda é o suficiente para diversas análises. E, como o número de dados nulos reduziu significativamente, fica mais fácil análisar e tratar os que restaram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b11b5",
   "metadata": {},
   "source": [
    "Percebemos que o valor de dados faltantes nos atributos _weekly_hosp_admissions_ e _weekly_hosp_admissions_per_million_ eram próximos ao tamanho total do _dataset_, por isso, removemos essas colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da57b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['weekly_hosp_admissions', 'weekly_hosp_admissions_per_million'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454610f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.isna().sum())\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc346621",
   "metadata": {},
   "source": [
    "Após analisar os atributos separadamente, decidimos atrubuir os valores faltantes através da média daquele atributo, naquele país e naquele mês. Caso não exista essa média, a mesma é considerada como a média do país. Se ainda assim a média não existir, a mesma é considerada como NaN e removida depois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "def get_start_and_end_month(data):\n",
    "    nextmonth = 1 if data.month == 12 else data.month + 1\n",
    "    year = data.year + 1 if nextmonth == 1 else data.year\n",
    "    end = pd.Timestamp(date(year, nextmonth, 1) - timedelta(days=1))\n",
    "    start = pd.Timestamp(date(data.year, data.month, 1))\n",
    "    \n",
    "    \n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_by_month_and_country_and_atribute(country, attribute, x):\n",
    "    start, end = get_start_and_end_month(x['date'])\n",
    "    \n",
    "    #print(f\"Processando iso_code {x['iso_code']} com a data {x['date']} para o atributo {attribute}\")\n",
    "    median = dataset.loc[(dataset['iso_code'] == country) & ((dataset['date'] >= start) | \n",
    "                         (dataset['date'] <= end)), attribute].median()\n",
    "    \n",
    "    if pd.isna(median) or median <= 0:\n",
    "        #print('Tentando agora a media do pais')\n",
    "        median = dataset.loc[dataset['iso_code'] == country, attribute].median()\n",
    "        \n",
    "    if pd.isna(median) or median <= 0:\n",
    "        median = dataset.loc[dataset['continent'] == x['continent'], attribute].median()\n",
    "        #print('Tentando media do continente')\n",
    "    \n",
    "    if pd.isna(median) or median <= 0:\n",
    "        #print(f'Impossivel inferir a media para o atributo {attribute}, usando NaN no lugar')\n",
    "        median = np.nan\n",
    "        \n",
    "    #print(f'Media calculada {median}')\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['new_cases'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d657459",
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_to_calc_median = ['hosp_patients', 'hosp_patients_per_million', 'new_cases_per_million', 'new_cases',\n",
    "                            'new_tests', 'total_tests', 'total_tests_per_thousand', 'new_tests_smoothed',\n",
    "                            'new_tests_smoothed_per_thousand', 'positive_rate', 'total_vaccinations',\n",
    "                            'people_vaccinated', 'people_fully_vaccinated', 'new_vaccinations', \n",
    "                            'new_vaccinations_smoothed', 'total_vaccinations_per_hundred',\n",
    "                            'people_vaccinated_per_hundred',  'people_fully_vaccinated_per_hundred',\n",
    "                            'new_vaccinations_smoothed_per_million', 'aged_70_older', 'gdp_per_capita', 'extreme_poverty',\n",
    "                            'female_smokers', 'male_smokers', 'handwashing_facilities', 'hospital_beds_per_thousand',\n",
    "                            'new_tests_per_thousand', 'reproduction_rate']\n",
    "\n",
    "for attribute in attributes_to_calc_median:\n",
    "    dataset.loc[dataset[attribute].isna(), attribute] = dataset[dataset[attribute].isna()].apply(lambda x: median_by_month_and_country_and_atribute(x['iso_code'], attribute, x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e686bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "print(dataset.isna().sum())\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758bac9e",
   "metadata": {},
   "source": [
    "Após todo o processamento dos dados, é possível perceber que a quantidade faltante é, literalmente, nula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7340eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bac276",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(dataset, figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2900c5e4",
   "metadata": {},
   "source": [
    "Agora, vamos converter os atributos categóricos para valores discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604c37fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categoricals = ['continent', 'location', 'iso_code']\n",
    "for column in categoricals:\n",
    "    text_label = LabelEncoder()\n",
    "    num_label = text_label.fit_transform(dataset[column])\n",
    "    dataset[column + '_lab'] = num_label\n",
    "dataset['dayofyear'] = dataset['date'].dt.dayofyear\n",
    "dataset.drop(columns=['continent', 'location', 'date', 'iso_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d2c23",
   "metadata": {},
   "source": [
    "A etapa anterior garantiu a existência de dados não nulos, mas vamos dar uma olhada em dados negativos agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd33aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataset.select_dtypes(include=[np.number]).columns:\n",
    "    min_value = np.min(dataset[column])\n",
    "    if min_value < 0:\n",
    "        num_rows = len(dataset.loc[dataset[column] < 0])\n",
    "        print(f\"Removing {num_rows} rows in {column} because this lines have a value less than 0.\")\n",
    "        dataset.drop(dataset.loc[dataset[column] < 0].index, inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a58371",
   "metadata": {},
   "source": [
    "Apenas garantindo que não exista nenhum valor estranho nas colunas numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in dataset.select_dtypes(include=[np.number]).columns:\n",
    "    min_value = np.min(dataset[column])\n",
    "    max_value = np.max(dataset[column])\n",
    "    print(f\"Column {column} have a min value of {min_value} and max value of {max_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b4ae0",
   "metadata": {},
   "source": [
    "Aqui, decidi que minha análise irá usar consistir em tentar prever novos casos, o que torna o atributo *new_cases* minha variável-alvo.\n",
    "\n",
    "Assim sendo, irei remover os atributos que não possuem forte correlação com essa variável-alvo'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = dataset.select_dtypes(include=[np.number]).columns.to_list()\n",
    "target_varible = 'new_cases'\n",
    "filtered_columns = [x for x in all_columns if x != target_varible]\n",
    "low_correlation = dict.fromkeys(filtered_columns, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c887c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for correlation in filtered_columns:\n",
    "    corr = dataset[target_varible].corr(dataset[correlation])\n",
    "    print(f\"Correlation between columns {target_varible} and {correlation} is {corr}\")\n",
    "    if corr < 0.3:\n",
    "        low_correlation[correlation] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf6efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c135c4",
   "metadata": {},
   "source": [
    "Aqui temos um fato curioso, onde os atributos *positive_rate*, *median_age*, *aged_65_older*, *aged_70_older*, *gdp_per_capita*, *female_smokers*, *male_smokers*, *handwashing_facilities*, *life_expectancy* e *human_development_index* não possuem uma forte correlação com as possíveis variáveis-alvo. Portanto, vamos remover esses atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb2398",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [key for key, value in low_correlation.items() if value == 1]\n",
    "dataset.drop(keys, inplace=True, axis=1)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ca4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 9))\n",
    "sns.heatmap(dataset.corr(), annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221dce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093b46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d9400",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff02d6b7",
   "metadata": {},
   "source": [
    "Finalmente, vamos salvar o resultado em um arquivo para usar no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc07c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('process.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-env",
   "language": "python",
   "name": "multi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
